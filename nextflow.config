
workDir =    "${projectDir}/work"
tmpDir =     "${projectDir}/tmp"

params {
  outdir =    "${projectDir}/results"
  reportdir = "${projectDir}/reports"
  tracedir = "${projectDir}/traceDir"
}

// Global default params, used in configs
params {

    // Max resource options
    // Defaults only, expecting to be overwritten
    max_memory                 = '128.GB'
    max_cpus                   = 16
    max_time                   = '240.h'

}
// Load base.config by default for all pipelines
includeConfig 'conf/base.config'

profiles {
    debug { process.beforeScript = 'echo $HOSTNAME' }

    singularity {
        singularity.enabled    = true
        singularity.autoMounts = true
        docker.enabled         = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
    }
    lsf {
        includeConfig 'conf/lsf_base.conf'
        includeConfig 'conf/lsf_tasks.conf'
    }
    lsf_tower{
        includeConfig 'conf/lsf_base.conf'
        includeConfig 'conf/lsf_tasks.conf'
    }
    test_lsf  { includeConfig 'conf/test_lsf.conf'}
}
// Export these variables to prevent local Python/R libraries from conflicting with those in the container
env {
    PYTHONNOUSERSITE = 1
    R_PROFILE_USER   = "/.Rprofile"
    R_ENVIRON_USER   = "/.Renviron"
}

// Capture exit codes from upstream processes when piping
process.shell = ['/bin/bash', '-euo', 'pipefail']

def trace_timestamp = new java.util.Date().format( 'yyyy-MM-dd_HH-mm-ss')

timeline {
    enabled = false
    file    = "${params.tracedir}/execution_timeline_${trace_timestamp}.html"
}
report {
    enabled = false
    file    = "${params.tracedir}/execution_report_${trace_timestamp}.html"
}
trace {
    enabled = false
    file    = "${params.tracedir}/execution_trace_${trace_timestamp}.txt"
}
dag {
    enabled = false
    file    = "${params.tracedir}/pipeline_dag_${trace_timestamp}.svg"
}

// Function to ensure that resource requirements don't go beyond
// a maximum limit
def check_max(obj, type) {
    if (type == 'memory') {
        try {
            if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
                return params.max_memory as nextflow.util.MemoryUnit
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'time') {
        try {
            if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
                return params.max_time as nextflow.util.Duration
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'cpus') {
        try {
            return Math.min( obj, params.max_cpus as int )
        } catch (all) {
            println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
            return obj
        }
    }
}



{"aGDSdir":"/lustre/scratch119/realdata/mdt2/projects/interval_wgs/analysis/STAARpipeline/data/input_test/agds_dir.Rdata",
"jobNum":"/lustre/scratch119/realdata/mdt2/projects/interval_wgs/analysis/STAARpipeline/data/input_test/jobs_num.Rdata",
"nullModel":"/lustre/scratch119/realdata/mdt2/projects/interval_wgs/analysis/STAARpipeline/results/Null_Model/obj.STAAR.fbc_neut.Rdata",
"nameCatalog":"/lustre/scratch119/realdata/mdt2/projects/interval_wgs/analysis/STAARpipeline/data/input/Annotation_name_catalog.txt",
"agdsFiles":"/lustre/scratch119/realdata/mdt2/projects/interval_wgs/final_release_freeze_GDS/gt_phased_Ensembl_regulatory_build/GDS_files/*.gds",
"max_cpus":16,
"max_memory":"128.GB",
"max_time":"240.h",
"outdir":"${projectDir}/results",
"reportdir":"${params.outdir}/reports",
"tracedir":"${params.outdir}/pipeline_info"}